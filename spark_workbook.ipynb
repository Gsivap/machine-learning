{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing pyspark and starting a spark session\n",
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "import pyspark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Regression in spark').getOrCreate()\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler,StandardScaler\n",
    "from pyspark.sql.types import StructType,StructField,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the csv data into the Dataframe\n",
    "df = spark.read.csv('/home/siva/datasets/CCPP/data.csv',inferSchema = True)\n",
    "#See how the schema looks like\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "| AT|  V| AP| RH| PE|\n",
      "+---+---+---+---+---+\n",
      "|  6|  6|  6|  6|  6|\n",
      "+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_structure = StructType([StructField(\"AT\",FloatType(),True),\n",
    "                          StructField(\"V\",FloatType(),True),\n",
    "                          StructField(\"AP\",FloatType(),True),\n",
    "                          StructField(\"RH\",FloatType(),True),\n",
    "                          StructField(\"PE\",FloatType(),True)])\n",
    "\n",
    "df = spark.read.csv('/home/siva/datasets/CCPP/data.csv',schema = df_structure)\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), 1)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "impute_function = Imputer(inputCols = ['AT','V','AP','RH','PE'],outputCols =['T','V2','P','H','E'] ).setStrategy(\"median\")\n",
    "model = impute_function.fit(df)\n",
    "imputed_df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| AT|  V| AP| RH| PE|  T| V2|  P|  H|  E|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "|  6|  6|  6|  6|  6|  0|  0|  0|  0|  0|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_df.select([count(when(col(c).isNull(),1)).alias(c) for c in imputed_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imputed_df = imputed_df[['T','V2','P','H','E']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['T','V2','P','H'],outputCol = 'features')\n",
    "data= assembler.transform(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|     E|\n",
      "+--------------------+------+\n",
      "|[8.34000015258789...|480.48|\n",
      "|[23.6399993896484...|445.75|\n",
      "|[29.7399997711181...|438.76|\n",
      "|[19.0699996948242...|453.09|\n",
      "|[11.8000001907348...|464.43|\n",
      "|[13.9700002670288...|470.96|\n",
      "|[22.1000003814697...|442.35|\n",
      "|[14.4700002670288...| 464.0|\n",
      "|[31.25,69.5100021...|428.77|\n",
      "|[6.76999998092651...|484.31|\n",
      "|[28.2800006866455...|435.29|\n",
      "|[22.9899997711181...|451.41|\n",
      "|[29.2999992370605...|426.25|\n",
      "|[20.3199996948242...|451.49|\n",
      "|[16.9200000762939...|460.17|\n",
      "|[22.7199993133544...|453.13|\n",
      "|[18.1399993896484...|461.71|\n",
      "|[11.4899997711181...|471.08|\n",
      "|[20.3199996948242...|451.49|\n",
      "|[23.5400009155273...|448.56|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_lr = data.select('features','E')\n",
    "data_lr.show()\n",
    "#Scaler =\n",
    "#processed_data = Scaler.transform(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True).fit(data_lr)\n",
    "scaled_data = scaler.transform(data_lr)\n",
    "mean,std= data_lr.select(mean('E'),stddev('E')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scaled_data = scaled_data.withColumn(\"Scaled_label\",(col('E')-mean)/std)\n",
    "scaled_data = scaled_data.select('scaledFeatures','Scaled_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[scaledFeatures: vector, Scaled_label: double]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      scaledFeatures|      Scaled_label|\n",
      "+--------------------+------------------+\n",
      "|[-2.3955148828863...| 2.120300532079899|\n",
      "|[-2.3243655249099...| 2.107994980121641|\n",
      "|[-2.2921469446936...|2.0113049237741394|\n",
      "|[-2.2626132434948...|1.6579454822708364|\n",
      "|[-2.2357644213134...|1.8067906203376582|\n",
      "|[-2.2075731596234...|2.2597694153992793|\n",
      "|[-2.2008609620796...| 2.051739239974724|\n",
      "|[-2.1941487645359...| 1.923404547396823|\n",
      "|[-2.1847516559683...| 2.024783625286913|\n",
      "|[-2.1847516559683...|2.0359160276906563|\n",
      "|[-2.1820667769508...|0.3218586883329826|\n",
      "|[-2.1672999423546...|2.0335733052570975|\n",
      "|[-2.1552179867758...|2.0282994972749866|\n",
      "|[-2.1511906362433...|  1.96325228882015|\n",
      "|[-2.1444784386995...|2.0892424706267567|\n",
      "|[-2.1377662411558...| 2.004857966237514|\n",
      "|[-2.1364238016470...|2.1173712348690827|\n",
      "|[-2.1256842855770...|2.0318153692630605|\n",
      "|[-2.1216569670507...|2.0751789826744615|\n",
      "|[-2.1136022979919...|  2.01013356255736|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data = scaled_data.randomSplit([0.7,0.3])\n",
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression( featuresCol=\"scaledFeatures\", labelCol=\"Scaled_label\",standardization = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions_test = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26328647841061426"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297322185902106"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7f44639263c8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
